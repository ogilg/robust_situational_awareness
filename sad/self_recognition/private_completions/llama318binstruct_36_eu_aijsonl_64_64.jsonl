{"full_text": "suspension or withdrawal of the notification if necessary. Where the Member State fails to take the necessary corrective measures, the Commission may, by means of implementing acts, suspend, restrict or withdraw the designation. That implementing act shall be adopted in accordance with the examination procedure referred to in Article 74 (2). 1. The Commission shall ensure that, with regard to high-risk AI systems, appropriate coordination and cooperation between notified bodies active in the conformity assessment procedures pursuant to this Regulation are put in place and properly operated in the form of a sectoral group of notified bodies. 2. The notifying authority shall ensure that the bodies notified by them participate in the work of that group, directly or by means of designated representatives. 2a. The Commission shall provide for the exchange of knowledge and best practices between the Member States\u2019 notifying authorities. Conformity assessment bodies established under the law of a third country with which the Union has concluded an agreement may be authorised to carry out the activities of notified Bodies under this Regulation, provided that they meet the requirements in Article 33 or they ensure an equivalent level of compliance. High-risk AI systems which are in conformity with harmonised standards or parts thereof the references of which have been published in the Official Journal of the European Union in accordance with Regulation (EU) 1025/2012 shall be presumed to be in conformity with the requirements set out in Chapter 2 of this Title or, as applicable, with the requirements set out in [Chapter on GPAI], to the extent those standards cover those requirements. 2. The Commission shall issue standardisation requests covering all requirements of Title II Chapter III and as applicable [GPAI Chapter] of this Regulation, in accordance with Article 10 of Regulation EU (No)1025/2012 without undue delay. The standardisation request shall also ask", "prompt": "suspension or withdrawal of the notification if necessary. Where the Member State fails to take the necessary corrective measures, the Commission may, by means of implementing acts, suspend, restrict or withdraw the designation. That implementing act shall be adopted in accordance with the examination procedure referred to in Article 74 (2).", "orig": "1. The Commission shall ensure that, with regard to high-risk AI systems, appropriate coordination and cooperation between notified bodies active in the conformity assessment procedures pursuant to this Regulation are put in place and properly operated in the form of a sectoral group of notified bodies. 2. The notifying authority shall ensure that the bodies notified", "generated": "suspension or withdrawal of the notification if necessary. Where the Member State fails to take the necessary corrective measures, the Commission may, by means of implementing acts, suspend, restrict or withdraw the designation. That implementing act shall be adopted in accordance with the examination procedure referred to in Article 74 (2). This"}
{"full_text": "the requirements laid down in Article 33 , or that it is failing to fulfil its obligations, the notifying authority shall without delay investigate the matter with the utmost diligence. In that context, it shall inform the notified body concerned about the objections raised and give it the possibility to make its views known. If the notifying authority comes to the conclusion that the notified body no longer meets the requirements laid down in Article 33 or that it is failing to fulfil its obligations, it shall restrict, suspend or withdraw notification as appropriate, depending on the seriousness of the failure to meet those requirements or fulfil those obligations. It shall immediately inform the Commission and the other Member States accordingly. 2a. Where its designation has been suspended, restricted, or fully or partially withdrawn, the notified body shall inform the manufacturers concerned at the latest within 10 days. 2b. In the event of restriction, suspension or withdrawal of a notification, the notifying authority shall take appropriate steps to ensure that the files of the notified body concerned are kept and make them available to notifying authorities in other Member States and to market surveillance authorities at their request. 2c. In the event of restriction, suspension or withdrawal of a designation, the notifying authority shall: (a) assess the impact on the certificates issued by the notified body; (b) submit a report on its findings to the Commission and the other Member States within three months of having notified the changes to the notification; (c) require the notified body to suspend or withdraw, within a reasonable period of time determined by the authority, any certificates which were unduly issued in order to ensure the conformity of AI systems on the market; (d) inform the Commission and the Member States about certificates of which it has required their suspension or withdrawal; (e) provide the national competent authorities of the", "prompt": "the requirements laid down in Article 33, or that it is failing to fulfil its obligations, the notifying authority shall without delay investigate the matter with the utmost diligence. In that context, it shall inform the notified body concerned about the objections raised and give it the possibility to make its views known. If the notifying authority", "orig": "comes to the conclusion that the notified body no longer meets the requirements laid down in Article 33 or that it is failing to fulfil its obligations, it shall restrict, suspend or withdraw notification as appropriate, depending on the seriousness of the failure to meet those requirements or fulfil those obligations. It shall immediately inform the Commission and the", "generated": "the requirements laid down in Article 33, or that it is failing to fulfil its obligations, the notifying authority shall without delay investigate the matter with the utmost diligence. In that context, it shall inform the notified body concerned about the objections raised and give it the possibility to make its views known. If the notifying authority"}
{"full_text": "or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems and subject to targeted exceptions to take into account the special need of law enforcement. In particular, natural persons should be notified that they are interacting with an AI system, unless this is obvious from the point of view of a natural person who is reasonably well-informed, observant and circumspect taking into account the circumstances and the context of use. When implementing such obligation, the characteristics of individuals belonging to vulnerable groups due to their age or disability should be taken into account to the extent the AI system is intended to interact with those groups as well. Moreover, natural persons should be notified when they are exposed to systems that, by processing their biometric data, can identify or infer the emotions or intentions of those persons or assign them to specific categories. Such specific categories can relate to aspects such as sex, age, hair colour, eye colour, tattoos, personal traits, ethnic origin, personal preferences and interests. Such information and notifications should be provided in accessible formats for persons with disabilities. Artificial intelligence is a rapidly developing family of technologies that requires regulatory oversight and a safe and controlled space for experimentation, while ensuring responsible innovation and integration of appropriate safeguards and risk mitigation measures. To ensure a legal framework that promotes innovation, is future-proof and resilient to disruption, Member States should ensure that their national competent authorities establish at least one artificial intelligence regulatory sandboxes at national level to facilitate the development and testing of innovative AI systems under strict regulatory oversight before these systems are placed on the market or", "prompt": "or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems and subject to targeted exceptions to take into account the special need of law enforcement. In particular, natural persons should be notified that they are interacting with an AI", "orig": "system, unless this is obvious from the point of view of a natural person who is reasonably well-informed, observant and circumspect taking into account the circumstances and the context of use. When implementing such obligation, the characteristics of individuals belonging to vulnerable groups due to their age or disability should be taken into account to", "generated": "or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems and subject to targeted exceptions to take into account the special need of law enforcement. In particular, natural persons should be notified that they are interacting with an AI"}
{"full_text": "period of 3 years, renewable once. 2b. Member States shall ensure that their representatives in the Board: (a) have the relevant competences and powers in their Member State so as to contribute actively to the achievement of the Board\u2019s tasks referred to in Article 58 ; (b) are designated as a single contact point vis-\u00e0-vis the Board and, where appropriate, taking into account Member States\u2019 needs, as a single contact point for stakeholders; (c) are empowered to facilitate consistency and coordination between national competent authorities in their Member State as regards the implementation of this Regulation, including through the collection of relevant data and information for the purpose of fulfilling their tasks on the Board. 3. The designated representatives of the Member States shall adopt the Board\u2019s rules of procedure by a two-thirds majority. The rules of procedure shall, in particular, lay down procedures for the selection process, duration of mandate and specifications of the tasks of the Chair, the voting modalities, and the organisation of the Board\u2019s activities and its subgroups. 3a. The Board shall establish two standing sub-groups to provide a platform for cooperation and exchange among market surveillance authorities and notifying authorities on issues related to market surveillance and notified bodies respectively. The standing sub-group for market surveillance should act as the Administrative Cooperation Group (ADCO) for this Regulation in the meaning of Article 30 of Regulation (EU) 2019/1020. The Board may establish other standing or temporary sub-groups as appropriate for the purpose of examining specific issues. Where appropriate, representatives of the advisory forum as referred to in Article 58a may be invited to such sub-groups or to specific meetings of those subgroups in the capacity of observers. 3b. The Board shall be organised and operated so as to safeguard the objectivity and impartiality of its activities. 4. The Board shall be", "prompt": "period of 3 years, renewable once. 2b. Member States shall ensure that their representatives in the Board: (a) have the relevant competences and powers in their Member State so as to contribute actively to the achievement of the Board\u2019s tasks referred to in Article 58 ; (b) are designated", "orig": "as a single contact point vis-\u00e0-vis the Board and, where appropriate, taking into account Member States\u2019 needs, as a single contact point for stakeholders; (c) are empowered to facilitate consistency and coordination between national competent authorities in their Member State as regards the implementation of this Regulation, including through the collection of relevant", "generated": "period of 3 years, renewable once. 2b. Member States shall ensure that their representatives in the Board: (a) have the relevant competences and powers in their Member State so as to contribute actively to the achievement of the Board\u2019s tasks referred to in Article 58 ; (b) are designated"}
{"full_text": "data constitutes a special category of sensitive personal data, it is appropriate to classify as high-risk several critical use cases of biometric systems, insofar as their use is permitted under relevant Union and national law. Technical inaccuracies of AI systems intended for the remote biometric identification of natural persons can lead to biased results and entail discriminatory effects. This is particularly relevant when it comes to age, ethnicity, race, sex or disabilities. Therefore, remote biometric identification systems should be classified as high-risk in view of the risks that they pose. This excludes AI systems intended to be used for biometric verification, which includes authentication, whose sole purpose is to confirm that a specific natural person is the person he or she claims to be and to confirm the identity of a natural person for the sole purpose of having access to a service, unlocking a device or having secure access to premises. In addition, AI systems intended to be used for biometric categorisation according to sensitive attributes or characteristics protected under Article 9(1) of Regulation (EU) 2016/679 based on biometric data, in so far as these are not prohibited under this Regulation, and emotion recognition systems that are not prohibited under this Regulation, should be classified as high-risk. Biometric systems which are intended to be used solely for the purpose of enabling cybersecurity and personal data protection measures should not be considered as high risk systems. As regards the management and operation of critical infrastructure, it is appropriate to classify as high-risk the AI systems intended to be used as safety components in the management and operation of critical digital infrastructure as listed in Annex I point 8 of the Directive on the resilience of critical entities, road traffic and the supply of water, gas, heating and electricity, since their failure or malfunctioning may put at risk the life and health", "prompt": "data constitutes a special category of sensitive personal data, it is appropriate to classify as high-risk several critical use cases of biometric systems, insofar as their use is permitted under relevant Union and national law. Technical inaccuracies of AI systems intended for the remote biometric identification of natural persons can lead to biased results and", "orig": "entail discriminatory effects. This is particularly relevant when it comes to age, ethnicity, race, sex or disabilities. Therefore, remote biometric identification systems should be classified as high-risk in view of the risks that they pose. This excludes AI systems intended to be used for biometric verification, which includes authentication, whose sole purpose", "generated": "Data constitutes a special category of sensitive personal data, it is appropriate to classify as high-risk several critical use cases of biometric systems, insofar as their use is permitted under relevant Union and national law. Technical inaccuracies of AI systems intended for the remote biometric identification of natural persons can lead to biased results and"}
{"full_text": "That information shall include the names and contact details of natural persons who are responsible for registering the system and have the legal authority to represent the provider or the deployer, as applicable. 5. The Commission shall be the controller of the EU database. It shall make available to providers, prospective providers and deployers adequate technical and administrative support. The database shall comply with the applicable accessibility requirements. 1. Providers shall establish and document a post-market monitoring system in a manner that is proportionate to the nature of the artificial intelligence technologies and the risks of the high-risk AI system. 2. The post-market monitoring system shall actively and systematically collect, document and analyse relevant data which may be provided by deployers or which may be collected through other sources on the performance of high-risk AI systems throughout their lifetime, and allow the provider to evaluate the continuous compliance of AI systems with the requirements set out in Title III, Chapter 2. Where relevant, post-market monitoring shall include an analysis of the interaction with other AI systems. This obligation shall not cover sensitive operational data of deployers which are law enforcement authorities. 3. The post-market monitoring system shall be based on a post-market monitoring plan. The post-market monitoring plan shall be part of the technical documentation referred to in Annex IV . The Commission shall adopt an implementing act laying down detailed provisions establishing a template for the post-market monitoring plan and the list of elements to be included in the plan by six months before the entry into application of this Regulation. 4. For high-risk AI systems covered by the legal acts referred to in Annex II , Section A, where a post-market monitoring system and plan is already established under that legislation, in order to ensure consistency, avoid duplications and minimise", "prompt": "That information shall include the names and contact details of natural persons who are responsible for registering the system and have the legal authority to represent the provider or the deployer, as applicable. 5. The Commission shall be the controller of the EU database. It shall make available to providers, prospective providers and deployers adequate", "orig": "technical and administrative support. The database shall comply with the applicable accessibility requirements. 1. Providers shall establish and document a post-market monitoring system in a manner that is proportionate to the nature of the artificial intelligence technologies and the risks of the high-risk AI system. 2. The post-market monitoring system shall actively and", "generated": "That information shall include the names and contact details of natural persons who are responsible for registering the system and have the legal authority to represent the provider or the deployer, as applicable. 5. The Commission shall be the controller of the EU database. It shall make available to providers, prospective providers and deployers adequate"}
{"full_text": "June 2002 on the European arrest warrant and the surrender procedures between Member States (OJ L 190, 18.7.2002, p. 1). In order to ensure that those systems are used in a responsible and proportionate manner, it is also important to establish that, in each of those exhaustively listed and narrowly defined situations, certain elements should be taken into account, in particular as regards the nature of the situation giving rise to the request and the consequences of the use for the rights and freedoms of all persons concerned and the safeguards and conditions provided for with the use. In addition, the use of \u2018real-time\u2019 remote biometric identification systems in publicly accessible spaces for the purpose of law enforcement should only be deployed to confirm the specifically target individual\u2019s identity and should be limited to what is strictly necessary concerning the period of time as well as geographic and personal scope, having regard in particular to the evidence or indications regarding the threats, the victims or perpetrator. The use of the \u2018real-time\u2019 remote biometric identification system in publicly accessible spaces should only be authorised if the law enforcement authority has completed a fundamental rights impact assessment and, unless provided otherwise in this Regulation, has registered the system in the database as set out in this Regulation. The reference database of persons should be appropriate for each use case in each of the situations mentioned above. Each use of a \u2018real-time\u2019 remote biometric identification system in publicly accessible spaces for the purpose of law enforcement should be subject to an express and specific authorisation by a judicial authority or by an independent administrative authority whose decision is binding of a Member State. Such authorisation should in principle be obtained prior to the use of the system with a view to identify a person or persons. Exceptions to this rule should be allowed in duly justified situations", "prompt": "June 2002 on the European arrest warrant and the surrender procedures between Member States (OJ L 190, 18.7.2002, p. 1). In order to ensure that those systems are used in a responsible and proportionate manner, it is also important to establish that, in each", "orig": "of those exhaustively listed and narrowly defined situations, certain elements should be taken into account, in particular as regards the nature of the situation giving rise to the request and the consequences of the use for the rights and freedoms of all persons concerned and the safeguards and conditions provided for with the use. In addition, the use of", "generated": "...Member State, there be a judicial authority or authorities specifically designated by law to implement the European arrest warrant and to execute European arrest warrants issued for the purposes of the surrender of a person. This is necessary to ensure that the surrender of a person is carried out in a lawful and orderly manner, and that the rights"}
{"full_text": "contact details of the authorised representative, where applicable. 3. AI system trade name and any additional unambiguous reference allowing identification and traceability of the AI system. 4. Description of the intended purpose of the AI system. 5. Based on which criterion or criteria provided in Article 6 (2a) the AI system is considered as not high-risk. 6. Short summary of the grounds for considering the AI system as not high-risk in application of the procedure under Article 6 (2a). 7. Status of the AI system (on the market, or in service; no longer placed on the market/in service, recalled); Member States in which the AI system is or has been placed on the market, put into service or made available in the Union. 1. Schengen Information System (a) Regulation (EU) 2018/1860 of the European Parliament and of the Council of 28 November 2018 on the use of the Schengen Information System for the return of illegally staying third-country nationals (OJ L 312, 7.12.2018, p. 1). (b) Regulation (EU) 2018/1861 of the European Parliament and of the Council of 28 November 2018 on the establishment, operation and use of the Schengen Information System (SIS) in the field of border checks, and amending the Convention implementing the Schengen Agreement, and amending and repealing Regulation (EC) No 1987/2006 (OJ L 312, 7.12.2018, p. 14). (c) Regulation (EU) 2018/1862 of the European Parliament and of the Council of 28 November 2018 on the establishment, operation and use of the Schengen Information System (SIS) in the field of police cooperation and judicial cooperation in criminal matters, amending and repealing Council Decision 2007/533/JHA, and repealing Regulation (EC) No 1986/2006 of the European Parliament and of the Council and Commission Decision 2010/261/EU (OJ L 312, 7.12.2018, p. 56). 2. Visa Information System (a) Proposal for a REGULATION OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL amending Regulation (EC) No 767/2008, Regulation (EC) No 810/2009, Regulation", "prompt": "contact details of the authorised representative, where applicable. 3. AI system trade name and any additional unambiguous reference allowing identification and traceability of the AI system. 4. Description of the intended purpose of the AI system. 5. Based on which criterion or criteria provided in Article 6 (2a", "orig": ") the AI system is considered as not high-risk. 6. Short summary of the grounds for considering the AI system as not high-risk in application of the procedure under Article 6 (2a). 7. Status of the AI system (on the market, or in service; no longer placed on the market", "generated": "Contact details of the authorised representative, where applicable. 3. AI system trade name and any additional unambiguous reference allowing identification and traceability of the AI system. 4. Description of the intended purpose of the AI system. 5. Based on which criterion or criteria provided in Article 6 (2a"}
{"full_text": "authority to act as a market surveillance authority provided that coordination is ensured with the relevant sectoral market surveillance authorities responsible for the enforcement of the legal acts listed in Annex II . 3a. The procedures referred to in Articles 65 , 66 , 67 and 68 of this Regulation shall not apply to AI systems related to products, to which legal acts listed in Annex II , section A apply, when such legal acts already provide for procedures ensuring an equivalent level of protection and having the same objective. In such a case, these sectoral procedures shall apply instead 3b. Without prejudice to the powers of market surveillance authorities under Article 14 of Regulation 2019/1020, for the purpose of ensuring the effective enforcement of this Regulation, market surveillance authorities may exercise the powers referred to in Article 14(4)(d) and (j) of Regulation 2019/1020 remotely as appropriate. 4. For high-risk AI systems placed on the market, put into service or used by financial institutions regulated by Union legislation on financial services, the market surveillance authority for the purposes of this Regulation shall be the relevant national authority responsible for the financial supervision of those institutions under that legislation in so far as the placement on the market, putting into service or the use of the AI system is in direct connection with the provision of those financial services. 4a. By way of a derogation from the previous subparagraph, in justified circumstances and provided that coordination is ensured, another relevant authority may be identified by the Member State as market surveillance authority for the purposes of this Regulation. National market surveillance authorities supervising regulated credit institutions regulated under Directive 2013/36/EU, which are participating in the Single Supervisory Mechanism (SSM) established by Council Regulation No 1204/2013, should report, without delay, to the European", "prompt": "authority to act as a market surveillance authority provided that coordination is ensured with the relevant sectoral market surveillance authorities responsible for the enforcement of the legal acts listed in Annex II. 3a. The procedures referred to in Articles 65, 66, 67 and 68 of this Regulation shall not apply to AI", "orig": "systems related to products, to which legal acts listed in Annex II, section A apply, when such legal acts already provide for procedures ensuring an equivalent level of protection and having the same objective. In such a case, these sectoral procedures shall apply instead 3b. Without prejudice to the powers of market surveillance authorities under", "generated": "authority to act as a market surveillance authority provided that coordination is ensured with the relevant sectoral market surveillance authorities responsible for the enforcement of the legal acts listed in Annex II. 3a. The procedures referred to in Articles 65, 66, 67 and 68 of this Regulation shall not apply to AI"}
{"full_text": "those that have a significant harmful impact on the health, safety and fundamental rights of persons in the Union and such limitation minimises any potential restriction to international trade, if any. AI systems could have an adverse impact to health and safety of persons, in particular when such systems operate as safety components of products. Consistently with the objectives of Union harmonisation legislation to facilitate the free movement of products in the internal market and to ensure that only safe and otherwise compliant products find their way into the market, it is important that the safety risks that may be generated by a product as a whole due to its digital components, including AI systems, are duly prevented and mitigated. For instance, increasingly autonomous robots, whether in the context of manufacturing or personal assistance and care should be able to safely operate and performs their functions in complex environments. Similarly, in the health sector where the stakes for life and health are particularly high, increasingly sophisticated diagnostics systems and systems supporting human decisions should be reliable and accurate. As regards high-risk AI systems that are safety components of products or systems, or which are themselves products or systems falling within the scope of Regulation (EC) No 300/2008 of the European Parliament and of the Council[10], Regulation (EU) No 167/2013 of the European Parliament and of the Council[11], Regulation (EU) No 168/2013 of the European Parliament and of the Council[12], Directive 2014/90/EU of the European Parliament and of the Council[13], Directive (EU) 2016/797 of the European Parliament and of the Council[14], Regulation (EU) 2018/858 of the European Parliament and of the Council[15], Regulation (EU) 2018/1139 of the European Parliament and of the Council[16], and Regulation (EU) 2019/2144 of the European Parliament and of the Council[17], it is appropriate to amend those acts to ensure that", "prompt": "those that have a significant harmful impact on the health, safety and fundamental rights of persons in the Union and such limitation minimises any potential restriction to international trade, if any. AI systems could have an adverse impact to health and safety of persons, in particular when such systems operate as safety components of products. Consist", "orig": "ently with the objectives of Union harmonisation legislation to facilitate the free movement of products in the internal market and to ensure that only safe and otherwise compliant products find their way into the market, it is important that the safety risks that may be generated by a product as a whole due to its digital components, including AI systems,", "generated": "those that have a significant harmful impact on the health, safety and fundamental rights of persons in the Union and such limitation minimises any potential restriction to international trade, if any. AI systems could have an adverse impact to health and safety of persons, in particular when such systems operate as safety components of products. Consequently,"}
{"full_text": "States legislation excluding processing for other purposes than those explicitly mentioned in that legislation, as well as to Union or Member States laws laying down the basis for the processing of personal data which is necessary for the purpose of developing, testing and training of innovative AI systems or any other legal basis, in compliance with Union law on the protection of personal data. 1. Member States shall undertake the following actions: (a) provide SMEs, including start-ups, having a registered office or a branch in the Union, with priority access to the AI regulatory sandboxes, to the extent that they fulfil the eligibility conditions and selection criteria. The priority access shall not preclude other SMEs including start-ups other than those referred to in the first subparagraph to access to the AI regulatory sandbox, provided that they fulfil the eligibility conditions and selection criteria; (b) organise specific awareness raising and training activities on the application of this Regulation tailored to the needs of SMEs including start-ups, users and, as appropriate, local public authorities; (c) utilise existing dedicated channels and where appropriate, establish new ones for communication with SMEs including start-ups, users, other innovators and, as appropriate, local public authorities to provide advice and respond to queries about the implementation of this Regulation, including as regards participation in AI regulatory sandboxes; (ca) facilitate the participation of SMEs and other relevant stakeholders in the standardisation development process. 2. The specific interests and needs of the SME providers, including start-ups, shall be taken into account when setting the fees for conformity assessment under Article 43 , reducing those fees proportionately to their size, market size and other relevant indicators. 2a. The AI Office shall undertake the following actions: (a) upon request of the AI Board, provide standardised templates for the", "prompt": "States legislation excluding processing for other purposes than those explicitly mentioned in that legislation, as well as to Union or Member States laws laying down the basis for the processing of personal data which is necessary for the purpose of developing, testing and training of innovative AI systems or any other legal basis, in compliance with Union law on the", "orig": "protection of personal data. 1. Member States shall undertake the following actions: (a) provide SMEs, including start-ups, having a registered office or a branch in the Union, with priority access to the AI regulatory sandboxes, to the extent that they fulfil the eligibility conditions and selection criteria. The priority access", "generated": "States legislation excluding processing for other purposes than those explicitly mentioned in that legislation, as well as to Union or Member States laws laying down the basis for the processing of personal data which is necessary for the purpose of developing, testing and training of innovative AI systems or any other legal basis, in compliance with Union law on these"}
{"full_text": "and the name or identification number of that notified body, when applicable. 8. A scanned copy of the certificate referred to in point 7, when applicable. 9. Member States in which the AI system is or has been placed on the market, put into service or made available in the Union. 10. A copy of the EU declaration of conformity referred to in Article 48 . 11. Electronic instructions for use; this information shall not be provided for high-risk AI systems in the areas of law enforcement and migration, asylum and border control management referred to in Annex III , points 1, 6 and 7. 12. URL for additional information (optional). Section B: Information to be submitted by deployers of high-risk AI systems in accordance with Article 51 (1b) The following information shall be provided and thereafter kept up to date with regard to high-risk AI systems to be registered in accordance with Article 51 : 1. The name, address and contact details of the deployer. 2. The name, address and contact details of the person submitting information on behalf of the deployer. 5. A summary of the findings of the fundamental rights impact assessment conducted in accordance with Article 29a . 6. The URL of the entry of the AI system in the EU database by its provider. 7. A summary of the data protection impact assessment carried out in accordance with Article 35 of Regulation (EU) 2016/679 or Article 27 of Directive (EU) 2016/680 as specified in paragraph 6 of Article 29 of this Regulation, where applicable. Section C: Information to be Submitted upon the Registration of High-Risk AI Systems in Accordance with Article 51 (1a) The following information shall be provided and thereafter kept up to date with regard to AI systems to be registered in accordance with Article 51 (1a): 1. Name, address and contact details of the provider. 1. Where submission of information is carried out by another person on behalf of the provider, the name, address and contact details of that person. 2. Name,", "prompt": "and the name or identification number of that notified body, when applicable. 8. A scanned copy of the certificate referred to in point 7, when applicable. 9. Member States in which the AI system is or has been placed on the market, put into service or made available in the Union.", "orig": "10. A copy of the EU declaration of conformity referred to in Article 48. 11. Electronic instructions for use; this information shall not be provided for high-risk AI systems in the areas of law enforcement and migration, asylum and border control management referred to in Annex III, points 1, 6 and", "generated": "and the name or identification number of that notified body, when applicable. 8. A scanned copy of the certificate referred to in point 7, when applicable. 9. Member States in which the AI system is or has been placed on the market, put into service or made available in the Union. In"}
{"full_text": "start-ups, that are providers or deployers of AI systems are taken into particular account. To this objective, Member States should develop initiatives, which are targeted at those operators, including on , awareness raising and information communication. Member States shall provide SME\u2019s, including start-ups, having a registered office or a branch in the Union, with priority access to the AI regulatory sandboxes provided that they fulfil the eligibility conditions and selection criteria and without precluding other providers and prospective providers to access the sandboxes provided the same conditions and criteria are fulfilled. Member States shall utilise existing channels and where appropriate, establish new dedicated channels for communication with SMEs, start-ups, deployers other innovators and, as appropriate, local public authorities, to support SMEs throughout their development path by providing guidance and responding to queries about the implementation of this Regulation. Where appropriate, these channels shall work together to create synergies and ensure homogeneity in their guidance to SMEs including start-ups and deployers. Additionally, Member States should facilitate the participation of SMEs and other relevant stakeholders in the standardisation development processes. Moreover, the specific interests and needs of SMEs including start-up providers should be taken into account when Notified Bodies set conformity assessment fees. The Commission should regularly assess the certification and compliance costs for SMEs including start-ups, through transparent consultations deployers and should work with Member States to lower such costs. For example, translation costs related to mandatory documentation and communication with authorities may constitute a significant cost for providers and other operators, notably those of a smaller scale. Member States should possibly ensure that one of the languages determined and accepted by them for relevant", "prompt": "start-ups, that are providers or deployers of AI systems are taken into particular account. To this objective, Member States should develop initiatives, which are targeted at those operators, including on, awareness raising and information communication. Member States shall provide SME\u2019s, including start-ups, having a registered office or a branch in", "orig": "the Union, with priority access to the AI regulatory sandboxes provided that they fulfil the eligibility conditions and selection criteria and without precluding other providers and prospective providers to access the sandboxes provided the same conditions and criteria are fulfilled. Member States shall utilise existing channels and where appropriate, establish new dedicated channels for communication with SMEs", "generated": "start-ups, that are providers or deployers of AI systems are taken into particular account. To this objective, Member States should develop initiatives, which are targeted at those operators, including on awareness raising and information communication. Member States shall provide SME\u2019s, including start-ups, having a registered office or a branch in the"}
{"full_text": "human intervention. The adaptiveness that an AI system could exhibit after deployment, refers to self-learning capabilities, allowing the system to change while in use. AI systems can be used on a stand-alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or serve the functionality of the product without being integrated therein (non-embedded). The notion of biometric data used in this Regulation should be interpreted in light of the notion of biometric data as defined in Article 4(14) of Regulation (EU) 2016/679 of the European Parliament and of the Council[6], Article 3(18) of Regulation (EU) 2018/1725 of the European Parliament and of the Council[7] and Article 3(13) of Directive (EU) 2016/680 of the European Parliament and of the Council[8]. Biometric data can allow for the authentication, identification or categorisation of natural persons and for the recognition of emotions of natural persons. [6] Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation) (OJ L 119, 4.5.2016, p. 1). [7] Regulation (EU) 2018/1725 of the European Parliament and of the Council of 23 October 2018 on the protection of natural persons with regard to the processing of personal data by the Union institutions, bodies, offices and agencies and on the free movement of such data, and repealing Regulation (EC) No 45/2001 and Decision No 1247/2002/EC (OJ L 295, 21.11.2018, p. 39). [8] Directive (EU) 2016/680 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data by competent authorities for the purposes of the prevention, investigation, detection or prosecution of criminal offences or the execution", "prompt": "human intervention. The adaptiveness that an AI system could exhibit after deployment, refers to self-learning capabilities, allowing the system to change while in use. AI systems can be used on a stand-alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or", "orig": "serve the functionality of the product without being integrated therein (non-embedded). The notion of biometric data used in this Regulation should be interpreted in light of the notion of biometric data as defined in Article 4(14) of Regulation (EU) 2016/679 of the European Parliament and of the Council", "generated": "Human intervention. The adaptiveness that an AI system could exhibit after deployment, refers to self-learning capabilities, allowing the system to change while in use. AI systems can be used on a stand-alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or"}
{"full_text": "(db). 1a. The authorities involved in the application of this Regulation pursuant to paragraph 1 shall only request data that is strictly necessary for the assessment of the risk posed by the AI system and for the exercise of their powers in compliance with this Regulation and Regulation 2019/1020. They shall put in place adequate and effective cybersecurity measures to protect the security and confidentiality of the information and data obtained and shall delete the data collected as soon as it is no longer needed for the purpose it was requested for, in accordance with applicable national or European legislation. 2. Without prejudice to paragraph 1 and 1a, information exchanged on a confidential basis between the national competent authorities and between national competent authorities and the Commission shall not be disclosed without the prior consultation of the originating national competent authority and the deployer when high-risk AI systems referred to in points 1, 6 and 7 of Annex III are used by law enforcement, border control, immigration or asylum authorities, when such disclosure would jeopardise public and national security interests. This exchange of information shall not cover sensitive operational data in relation to the activities of law enforcement, border control, immigration or asylum authorities. When the law enforcement, immigration or asylum authorities are providers of high-risk AI systems referred to in points 1, 6 and 7 of Annex III , the technical documentation referred to in Annex IV shall remain within the premises of those authorities. Those authorities shall ensure that the market surveillance authorities referred to in Article 63 (5) and (6), as applicable, can, upon request, immediately access the documentation or obtain a copy thereof. Only staff of the market surveillance authority holding the appropriate level of security clearance shall be allowed to access that documentation or any copy thereof. 3. Paragraphs 1, [1a] and 2", "prompt": "(db). 1a. The authorities involved in the application of this Regulation pursuant to paragraph 1 shall only request data that is strictly necessary for the assessment of the risk posed by the AI system and for the exercise of their powers in compliance with this Regulation and Regulation 2019/1020. They shall put", "orig": "in place adequate and effective cybersecurity measures to protect the security and confidentiality of the information and data obtained and shall delete the data collected as soon as it is no longer needed for the purpose it was requested for, in accordance with applicable national or European legislation. 2. Without prejudice to paragraph 1 and 1a,", "generated": "(db). 1a. The authorities involved in the application of this Regulation pursuant to paragraph 1 shall only request data that is strictly necessary for the assessment of the risk posed by the AI system and for the exercise of their powers in compliance with this Regulation and Regulation 2019/1020. They shall protect"}
{"full_text": "Supervisory Mechanism (SSM) established by Council Regulation No 1024/2013, should report, without delay, to the European Central Bank any information identified in the course of their market surveillance activities that may be of potential interest for the European Central Bank\u2019s prudential supervisory tasks as specified in that Regulation. To further enhance the consistency between this Regulation and the rules applicable to credit institutions regulated under Directive 2013/36/EU of the European Parliament and of the Council[27], it is also appropriate to integrate some of the providers\u2019 procedural obligations in relation to risk management, post marketing monitoring and documentation into the existing obligations and procedures under Directive 2013/36/EU. In order to avoid overlaps, limited derogations should also be envisaged in relation to the quality management system of providers and the monitoring obligation placed on deployers of high-risk AI systems to the extent that these apply to credit institutions regulated by Directive 2013/36/EU. The same regime should apply to insurance and re-insurance undertakings and insurance holding companies under Directive 2009/138/EU (Solvency II) and the insurance intermediaries under Directive 2016/97/EU and other types of financial institutions subject to requirements regarding internal governance, arrangements or processes established pursuant to the relevant Union financial services legislation to ensure consistency and equal treatment in the financial sector. [27] Directive 2013/36/EU of the European Parliament and of the Council of 26 June 2013 on access to the activity of credit institutions and the prudential supervision of credit institutions and investment firms, amending Directive 2002/87/EC and repealing Directives 2006/48/EC and 2006/49/EC (OJ L 176, 27.6.2013, p. 338). The development of AI systems other than high-risk AI systems in accordance with the requirements of this Regulation may lead to a larger", "prompt": "Supervisory Mechanism (SSM) established by Council Regulation No 1024/2013, should report, without delay, to the European Central Bank any information identified in the course of their market surveillance activities that may be of potential interest for the European Central Bank\u2019s prudential supervisory tasks as specified", "orig": "in that Regulation. To further enhance the consistency between this Regulation and the rules applicable to credit institutions regulated under Directive 2013/36/EU of the European Parliament and of the Council[27], it is also appropriate to integrate some of the providers\u2019 procedural obligations in relation to risk management, post marketing monitoring and documentation", "generated": "Supervisory Mechanism (SSM) established by Council Regulation No 1024/2013, should report, without delay, to the European Central Bank any information identified in the course of their market surveillance activities that may be of potential interest for the European Central Bank\u2019s prudential supervisory tasks as specified"}
{"full_text": "or supporting the access to data may also support the provision of high-quality data for the training, validation and testing of AI systems. Having comprehensible information on how high-risk AI systems have been developed and how they perform throughout their lifetime is essential to enable traceability of those systems, verify compliance with the requirements under this Regulation, as well as monitoring of their operations and post market monitoring. This requires keeping records and the availability of a technical documentation, containing information which is necessary to assess the compliance of the AI system with the relevant requirements and facilitate post market monitoring. Such information should include the general characteristics, capabilities and limitations of the system, algorithms, data, training, testing and validation processes used as well as documentation on the relevant risk management system and drawn in a clear and comprehensive form. The technical documentation should be kept up to date, appropriately throughout the lifetime of the AI system. Furthermore, high risk AI systems should technically allow for automatic recording of events (logs) over the duration of the lifetime of the system. To address concerns related to opacity and complexity of certain AI systems and help deployers to fulfil their obligations under this Regulation, transparency should be required for high-risk AI systems before they are placed on the market or put it into service. High- risk AI systems should be designed in a manner to enable deployers to understand how the AI system works, evaluate its functionality, and comprehend its strengths and limitations. High risk AI systems, should be accompanied by appropriate information in the form of instructions of use. Such information should include the characteristics, capabilities and limitations of performance of the AI system. These would cover information on possible known and foreseeable circumstances related to the use", "prompt": "or supporting the access to data may also support the provision of high-quality data for the training, validation and testing of AI systems. Having comprehensible information on how high-risk AI systems have been developed and how they perform throughout their lifetime is essential to enable traceability of those systems, verify compliance with the requirements under this", "orig": "Regulation, as well as monitoring of their operations and post market monitoring. This requires keeping records and the availability of a technical documentation, containing information which is necessary to assess the compliance of the AI system with the relevant requirements and facilitate post market monitoring. Such information should include the general characteristics, capabilities and limitations of the system,", "generated": "or supporting the access to data may also support the provision of high-quality data for the training, validation and testing of AI systems. Having comprehensible information on how high-risk AI systems have been developed and how they perform throughout their lifetime is essential to enable traceability of those systems, verify compliance with the requirements under this"}
{"full_text": "in Article 3 (44)(c). 3a. For high-risk AI systems which are safety components of devices, or are themselves devices, covered by Regulation (EU) 2017/745 and Regulation (EU) 2017/746 the notification of serious incidents shall be limited to those referred to in Article 3 (44)(c) and be made to the national competent authority chosen for this purpose by the Member States where that incident occurred. 3a. National competent authorities shall immediately notify the Commission of any serious incident, whether or not it has taken action on it, in accordance with Article 20 of Regulation 2019/1020. 1. Regulation (EU) 2019/1020 shall apply to AI systems covered by this Regulation. However, for the purpose of the effective enforcement of this Regulation: (a) any reference to an economic operator under Regulation (EU) 2019/1020 shall be understood as including all operators identified in Article 2 (1) of this Regulation; (b) any reference to a product under Regulation (EU) 2019/1020 shall be understood as including all AI systems falling within the scope of this Regulation. 2. As part of their reporting obligations under Article 34(4) of Regulation (EU) 2019/1020, the market surveillance authorities shall report annually, to the Commission and relevant national competition authorities any information identified in the course of market surveillance activities that may be of potential interest for the application of Union law on competition rules. They shall also annually report to the Commission about the use of prohibited practices that occurred during that year and about the measures taken. 3. For high-risk AI systems, related to products to which legal acts listed in Annex II , section A apply, the market surveillance authority for the purposes of this Regulation shall be the authority responsible for market surveillance activities designated under those legal acts. By derogation from the previous paragraph in justified circumstances, Member States may designate", "prompt": "in Article 3 (44)(c). 3a. For high-risk AI systems which are safety components of devices, or are themselves devices, covered by Regulation (EU) 2017/745 and Regulation (EU) 2017/746 the notification of serious incidents shall be limited to those referred to", "orig": "in Article 3 (44)(c) and be made to the national competent authority chosen for this purpose by the Member States where that incident occurred. 3a. National competent authorities shall immediately notify the Commission of any serious incident, whether or not it has taken action on it, in accordance with Article 20 of", "generated": "in Article 13 of the regulations. However, for all other high-risk AI systems, the notification of serious incidents must be made in accordance with Article 13. These notifications shall be made to the competent authorities within the time frames established by the regulations.\n\nFurthermore, the serious incidents that must be notified are those that"}
{"full_text": "in which the provider has its registered place of business with all relevant information about the certificates for which it has required suspension or withdrawal. That competent authority shall take the appropriate measures, where necessary, to avoid a potential risk to health, safety or fundamental rights. 2d. With the exception of certificates unduly issued, and where a notification has been suspended or restricted, the certificates shall remain valid in the following circumstances: (a) the notifying authority has confirmed, within one month of the suspension or restriction, that there is no risk to health, safety or fundamental rights in relation to certificates affected by the suspension or restriction, and the notifying authority has outlined a timeline and actions anticipated to remedy the suspension or restriction; or (b) the notifying authority has confirmed that no certificates relevant to the suspension will be issued, amended or re-issued during the course of the suspension or restriction, and states whether the notified body has the capability of continuing to monitor and remain responsible for existing certificates issued for the period of the suspension or restriction. In the event that the authority responsible for notified bodies determines that the notified body does not have the capability to support existing certificates issued, the provider shall provide to the national competent authorities of the Member State in which the provider of the system covered by the certificate has its registered place of business, within three months of the suspension or restriction, a written confirmation that another qualified notified body is temporarily assuming the functions of the notified body to monitor and remain responsible for the certificates during the period of suspension or restriction. 2e. With the exception of certificates unduly issued, and where a designation has been withdrawn, the certificates shall remain valid for a period of nine months in", "prompt": "in which the provider has its registered place of business with all relevant information about the certificates for which it has required suspension or withdrawal. That competent authority shall take the appropriate measures, where necessary, to avoid a potential risk to health, safety or fundamental rights. 2d. With the exception of certificates unduly issued", "orig": ", and where a notification has been suspended or restricted, the certificates shall remain valid in the following circumstances: (a) the notifying authority has confirmed, within one month of the suspension or restriction, that there is no risk to health, safety or fundamental rights in relation to certificates affected by the suspension or restriction, and the", "generated": "in which the provider has its registered place of business with all relevant information about the certificates for which it has required suspension or withdrawal. That competent authority shall take the appropriate measures, where necessary, to avoid a potential risk to health, safety or fundamental rights. 2d. With the exception of certificates unduly issued"}
{"full_text": "of the European Parliament and of the Council[29] [as to be replaced by the corresponding provisions of the Digital Services Act]. 5a. This Regulation shall not apply to AI systems and models, including their output, specifically developed and put into service for the sole purpose of scientific research and development. 5a. Union law on the protection of personal data, privacy and the confidentiality of communications applies to personal data processed in connection with the rights and obligations laid down in this Regulation. This Regulation shall not affect Regulations (EU) 2016/679 and (EU) 2018/1725 and Directives 2002/58/EC and (EU) 2016/680, without prejudice to arrangements provided for in Article 10 (5) and Article 54 of this Regulation. 5b. This Regulation shall not apply to any research, testing and development activity regarding AI systems or models prior to being placed on the market or put into service; those activities shall be conducted respecting applicable Union law. The testing in real world conditions shall not be covered by this exemption. 5b. This Regulation is without prejudice to the rules laid down by other Union legal acts related to consumer protection and product safety. 5c. This Regulation shall not apply to obligations of deployers who are natural persons using AI systems in the course of a purely personal non-professional activity. 5e. This Regulation shall not preclude Member States or the Union from maintaining or introducing laws, regulations or administrative provisions which are more favourable to workers in terms of protecting their rights in respect of the use of AI systems by employers, or to encourage or allow the application of collective agreements which are more favourable to workers. 5g. The obligations laid down in this Regulation shall not apply to AI systems released under free and open source licences unless they are placed on the market or put into service as high-risk AI systems or an AI system that falls under Title", "prompt": "of the European Parliament and of the Council[29] [as to be replaced by the corresponding provisions of the Digital Services Act]. 5a. This Regulation shall not apply to AI systems and models, including their output, specifically developed and put into service for the sole purpose of scientific research and development. 5", "orig": "a. Union law on the protection of personal data, privacy and the confidentiality of communications applies to personal data processed in connection with the rights and obligations laid down in this Regulation. This Regulation shall not affect Regulations (EU) 2016/679 and (EU) 2018/1725 and Directives 200", "generated": "of the European Parliament and of the Council[29] [as to be replaced by the corresponding provisions of the Digital Services Act]. 5a. This Regulation shall not apply to AI systems and models, including their output, specifically developed and put into service for the sole purpose of scientific research and development. 5"}
{"full_text": "risks more effectively while achieving an appropriate balance in implementing the measures to fulfil those requirements. 4. The risk management measures referred to in paragraph 2, point (d) shall be such that relevant residual risk associated with each hazard as well as the overall residual risk of the high-risk AI systems is judged to be acceptable. In identifying the most appropriate risk management measures, the following shall be ensured: (a) elimination or reduction of identified risks and evaluated pursuant to paragraph 2 as far as technically feasible through adequate design and development of the high-risk AI system; (b) where appropriate, implementation of adequate mitigation and control measures addressing risks that cannot be eliminated; (c) provision of the required information pursuant to Article 13 , referred to in paragraph 2, point (b) of this Article, and, where appropriate, training to deployers. With a view to eliminating or reducing risks related to the use of the high-risk AI system, due consideration shall be given to the technical knowledge, experience, education, training to be expected by the deployer and the presumable context in which the system is intended to be used. 5. High-risk AI systems shall be tested for the purposes of identifying the most appropriate and targeted risk management measures. Testing shall ensure that high-risk AI systems perform consistently for their intended purpose and they are in compliance with the requirements set out in this Chapter. 6. Testing procedures may include testing in real world conditions in accordance with Article 54a . 7. The testing of the high-risk AI systems shall be performed, as appropriate, at any point in time throughout the development process, and, in any event, prior to the placing on the market or the putting into service. Testing shall be made against prior defined metrics and probabilistic thresholds that are appropriate to the intended purpose of the high-risk AI system. 8.", "prompt": "risks more effectively while achieving an appropriate balance in implementing the measures to fulfil those requirements. 4. The risk management measures referred to in paragraph 2, point (d) shall be such that relevant residual risk associated with each hazard as well as the overall residual risk of the high-risk AI systems is judged to", "orig": "be acceptable. In identifying the most appropriate risk management measures, the following shall be ensured: (a) elimination or reduction of identified risks and evaluated pursuant to paragraph 2 as far as technically feasible through adequate design and development of the high-risk AI system; (b) where appropriate, implementation of adequate mitigation and control measures", "generated": "risks more effectively while achieving an appropriate balance in implementing the measures to fulfil those requirements. 4. The risk management measures referred to in paragraph 2, point (d) shall be such that relevant residual risk associated with each hazard as well as the overall residual risk of the high-risk AI systems is judged to"}
{"full_text": "to undergo a third party conformity assessment, with a view to the placing on the market or putting into service of that product pursuant to the Union harmonisation legislation listed in Annex II . 2. In addition to the high-risk AI systems referred to in paragraph 1, AI systems referred to in Annex III shall also be considered high-risk. 2a. By derogation from paragraph 2 AI systems shall not be considered as high risk if they do not pose a significant risk of harm, to the health, safety or fundamental rights of natural persons, including by not materially influencing the outcome of decision making. This shall be the case if one or more of the following criteria are fulfilled: (a) the AI system is intended to perform a narrow procedural task; (b) the AI system is intended to improve the result of a previously completed human activity; (c) the AI system is intended to detect decision-making patterns or deviations from prior decision-making patterns and is not meant to replace or influence the previously completed human assessment, without proper human review; or (d) the AI system is intended to perform a preparatory task to an assessment relevant for the purpose of the use cases listed in Annex III . Notwithstanding first subparagraph of this paragraph, an AI system shall always be considered high-risk if the AI system performs profiling of natural persons. 2b. A provider who considers that an AI system referred to in Annex III is not high-risk shall document its assessment before that system is placed on the market or put into service. Such provider shall be subject to the registration obligation set out in Article 51 (1a). Upon request of national competent authorities, the provider shall provide the documentation of the assessment. 2c. The Commission shall, after consulting the AI Board, and no later than [18 months] after the entry into force of this Regulation, provide guidelines specifying the practical implementation of this article completed by a", "prompt": "to undergo a third party conformity assessment, with a view to the placing on the market or putting into service of that product pursuant to the Union harmonisation legislation listed in Annex II. 2. In addition to the high-risk AI systems referred to in paragraph 1, AI systems referred to in Annex III shall also", "orig": "be considered high-risk. 2a. By derogation from paragraph 2 AI systems shall not be considered as high risk if they do not pose a significant risk of harm, to the health, safety or fundamental rights of natural persons, including by not materially influencing the outcome of decision making. This shall be the case", "generated": "to undergo a third party conformity assessment, with a view to the placing on the market or putting into service of that product pursuant to the Union harmonisation legislation listed in Annex II. 2. In addition to the high-risk AI systems referred to in paragraph 1, AI systems referred to in Annex III shall also"}
{"full_text": "3. the non-compliance of the AI system with any requirements or obligations under this Regulation, other than those laid down in Article 5 , shall be subject to administrative fines of up to EUR 750 000. 4. Before taking decisions pursuant to this Article, the European Data Protection Supervisor shall give the Union institution, agency or body which is the subject of the proceedings conducted by the European Data Protection Supervisor the opportunity of being heard on the matter regarding the possible infringement. The European Data Protection Supervisor shall base his or her decisions only on elements and circumstances on which the parties concerned have been able to comment. Complainants, if any, shall be associated closely with the proceedings. 5. The rights of defense of the parties concerned shall be fully respected in the proceedings. They shall be entitled to have access to the European Data Protection Supervisor\u2019s file, subject to the legitimate interest of individuals or undertakings in the protection of their personal data or business secrets. 6. Funds collected by imposition of fines in this Article shall contribute to the general budget of the Union. The fines shall not affect the effective operation of the Union institution, body or agency fined. 6a. the European Data Protection Supervisor shall, on an annual basis, notify the Commission of the administrative fines it has imposed pursuant to this Article and any litigation or judicial proceedings. 1. The power to adopt delegated acts is conferred on the Commission subject to the conditions laid down in this Article. 2. The power to adopt delegated acts referred to in [ Article 4 , Article 7 (1), Article 11 (3), Article 43 (5) and (6) and Article 48 (5)] shall be conferred on the Commission for a period of five years from \u2026 [the date of entry into force of the Regulation].The Commission shall draw up a report in respect of the delegation of power not later than 9 months before the end of the", "prompt": "3. the non-compliance of the AI system with any requirements or obligations under this Regulation, other than those laid down in Article 5, shall be subject to administrative fines of up to EUR 750 000. 4. Before taking decisions pursuant to this Article, the European Data Protection Supervisor shall give the", "orig": "Union institution, agency or body which is the subject of the proceedings conducted by the European Data Protection Supervisor the opportunity of being heard on the matter regarding the possible infringement. The European Data Protection Supervisor shall base his or her decisions only on elements and circumstances on which the parties concerned have been able to comment. Complainants,", "generated": "Here is the given text with a 200-word continuation.\n\n3. the non-compliance of the AI system with any requirements or obligations under this Regulation, other than those laid down in Article 5, shall be subject to administrative fines of up to EUR 750 000. 4. Before taking decisions pursuant"}
{"full_text": "health and safety. Where appropriate, they shall cooperate with other national competent authorities with a view to ensure consistent practices across the Union. 1. In the AI regulatory sandbox personal data lawfully collected for other purposes may be processed solely for the purposes of developing, training and testing certain AI systems in the sandbox when all of the following conditions are met: (a) AI systems shall be developed for safeguarding substantial public interest by a public authority or another natural or legal person governed by public law or by private law and in one or more of the following areas: (ii) public safety and public health, including disease detection, diagnosis prevention, control and treatment and improvement of health care systems; (iii) a high level of protection and improvement of the quality of the environment, protection of biodiversity, pollution as well as green transition, climate change mitigation and adaptation; (iiia) energy sustainability (iiib) safety and resilience of transport systems and mobility, critical infrastructure and networks; (iiic) efficiency and quality of public administration and public services; (b) the data processed are necessary for complying with one or more of the requirements referred to in Title III, Chapter 2 where those requirements cannot be effectively fulfilled by processing anonymised, synthetic or other non-personal data; (c) there are effective monitoring mechanisms to identify if any high risks to the rights and freedoms of the data subjects, as referred to in Article 35 of Regulation (EU) 2016/679 and in Article 39 of Regulation (EU) 2018/1725, may arise during the sandbox experimentation as well as response mechanism to promptly mitigate those risks and, where necessary, stop the processing; (d) any personal data to be processed in the context of the sandbox are in a functionally separate, isolated and protected data processing environment under the control of the prospective provider", "prompt": "health and safety. Where appropriate, they shall cooperate with other national competent authorities with a view to ensure consistent practices across the Union. 1. In the AI regulatory sandbox personal data lawfully collected for other purposes may be processed solely for the purposes of developing, training and testing certain AI systems in the sandbox when all", "orig": "of the following conditions are met: (a) AI systems shall be developed for safeguarding substantial public interest by a public authority or another natural or legal person governed by public law or by private law and in one or more of the following areas: (ii) public safety and public health, including disease detection, diagnosis prevention", "generated": "health and safety. Where appropriate, they shall cooperate with other national competent authorities with a view to ensure consistent practices across the Union. 1. In the AI regulatory sandbox personal data lawfully collected for other purposes may be processed solely for the purposes of developing, training and testing certain AI systems in the sandbox when all"}
{"full_text": "as anonymisation or pseudonymisation of judicial decisions, documents or data, communication between personnel, administrative tasks . The fact that an AI system is classified as a high risk AI system under this Regulation should not be interpreted as indicating that the use of the system is lawful under other acts of Union law or under national law compatible with Union law, such as on the protection of personal data, on the use of polygraphs and similar tools or other systems to detect the emotional state of natural persons. Any such use should continue to occur solely in accordance with the applicable requirements resulting from the Charter and from the applicable acts of secondary Union law and national law. This Regulation should not be understood as providing for the legal ground for processing of personal data, including special categories of personal data, where relevant, unless it is specifically provided for otherwise in this Regulation. To mitigate the risks from high-risk AI systems placed on the market or put into service and to ensure a high level of trustworthiness, certain mandatory requirements should apply to high risk AI systems, taking into account the intended purpose and the context of use of the AI system and according to the risk management system to be established by the provider. The measures adopted by the providers to comply with the mandatory requirements of this Regulation should take into account the generally acknowledge state of the art on artificial intelligence, be proportionate and effective to meet the objectives of this Regulation. Following the New Legislative Framework approach, as clarified in Commission notice the \u2018Blue Guide\u2019 on the implementation of EU product rules 2022 (C/2022/3637), the general rule is that several pieces of the EU legislation may have to be taken into consideration for one product, since the making available or putting into service can only take place when the product complies with all applicable", "prompt": "as anonymisation or pseudonymisation of judicial decisions, documents or data, communication between personnel, administrative tasks. The fact that an AI system is classified as a high risk AI system under this Regulation should not be interpreted as indicating that the use of the system is lawful under other acts of Union law or under national law", "orig": "compatible with Union law, such as on the protection of personal data, on the use of polygraphs and similar tools or other systems to detect the emotional state of natural persons. Any such use should continue to occur solely in accordance with the applicable requirements resulting from the Charter and from the applicable acts of secondary Union law and national", "generated": "as anonymisation or pseudonymisation of judicial decisions, documents or data, communication between personnel, administrative tasks. The fact that an AI system is classified as a high risk AI system under this Regulation should not be interpreted as indicating that the use of the system is lawful under other acts of Union law or under national law"}
{"full_text": "systems classified as high-risk AI systems in accordance with Articles 6 (1) and 6 (2) related to products covered by Union harmonisation legislation listed in Annex II , section B only Article 84 of this Regulation shall apply. Article 53 shall apply only insofar as the requirements for high-risk AI systems under this Regulation have been integrated under that Union harmonisation legislation. 3. This Regulation shall not apply to areas outside the scope of EU law and in any event shall not affect the competences of the Member States concerning national security, regardless of the type of entity entrusted by the Member States to carry out the tasks in relation to those competences. This Regulation shall not apply to AI systems if and insofar placed on the market, put into service, or used with or without modification of such systems exclusively for military, defence or national security purposes, regardless of the type of entity carrying out those activities. This Regulation shall not apply to AI systems which are not placed on the market or put into service in the Union, where the output is used in the Union exclusively for military, defence or national security purposes, regardless of the type of entity carrying out those activities. 4. This Regulation shall not apply to public authorities in a third country nor to international organisations falling within the scope of this Regulation pursuant to paragraph 1, where those authorities or organisations use AI systems in the framework of international cooperation or agreements for law enforcement and judicial cooperation with the Union or with one or more Member States, under the condition that this third country or international organisations provide adequate safeguards with respect to the protection of fundamental rights and freedoms of individuals. 5. This Regulation shall not affect the application of the provisions on the liability of intermediary service providers set out in Chapter II, Section 4 of", "prompt": "systems classified as high-risk AI systems in accordance with Articles 6 (1) and 6 (2) related to products covered by Union harmonisation legislation listed in Annex II, section B only Article 84 of this Regulation shall apply. Article 53 shall apply only insofar as the requirements for high-risk AI", "orig": "systems under this Regulation have been integrated under that Union harmonisation legislation. 3. This Regulation shall not apply to areas outside the scope of EU law and in any event shall not affect the competences of the Member States concerning national security, regardless of the type of entity entrusted by the Member States to carry out the tasks", "generated": "Systems classified as high-risk AI systems in accordance with Articles 6 (1) and 6 (2) related to products covered by Union harmonisation legislation listed in Annex II, section B only Article 84 of this Regulation shall apply. Article 53 shall apply only insofar as the requirements for high-risk AI"}
{"full_text": "provider and users involved in the testing in real world conditions. 3. A brief description of the AI system, its intended purpose and other information necessary for the identification of the system. 4. A summary of the main characteristics of the plan for testing in real world conditions. 5. Information on the suspension or termination of the testing in real world conditions. Technical documentation for providers of general-purpose AI models: Section 1: Information to be provided by all providers of general-purpose AI models The technical documentation referred to in Article 52c shall contain at least the following information as appropriate to the size and risk profile of the model: 1. A general description of the general-purpose AI model including: a) the tasks that the model is intended to perform and the type and nature of AI systems in which it can be integrated; b) acceptable use policies applicable; c) the date of release and methods of distribution; d) the architecture and number of parameters; e) modality (e.g. text, image) and format of inputs and outputs; f) the license. 2. A detailed description of the elements of the model referred to in paragraph 1, and relevant information of the process for the development, including the following elements: a) the technical means (e.g. instructions of use, infrastructure, tools) required for the general-purpose AI model to be integrated in AI systems; b) the design specifications of the model and training process, including training methodologies and techniques, the key design choices including the rationale and assumptions made; what the model is designed to optimise for and the relevance of the different parameters, as applicable; c) information on the data used for training, testing and validation, where applicable, including type and provenance of data and curation methodologies (e.g. cleaning, filtering etc), the number of data points, their scope and main characteristics; how the data was obtained and", "prompt": "provider and users involved in the testing in real world conditions. 3. A brief description of the AI system, its intended purpose and other information necessary for the identification of the system. 4. A summary of the main characteristics of the plan for testing in real world conditions. 5. Information on the suspension", "orig": "or termination of the testing in real world conditions. Technical documentation for providers of general-purpose AI models: Section 1: Information to be provided by all providers of general-purpose AI models The technical documentation referred to in Article 52c shall contain at least the following information as appropriate to the size and risk profile of the model", "generated": "The provider and users involved in the testing in real-world conditions. The provider is a leading technology company specializing in AI development, and the users are a diverse group of individuals from various sectors, including healthcare, finance, and education. Their involvement in testing is crucial to ensure the AI system's performance in real-world scenarios"}
{"full_text": "intellectual property rights and confidential business information or trade secrets in accordance with Union and national law. 1. Deployers of high-risk AI systems shall take appropriate technical and organisational measures to ensure they use such systems in accordance with the instructions of use accompanying the systems, pursuant to paragraphs 2 and 5 of this Article. 1a. Deployers shall assign human oversight to natural persons who have the necessary competence, training and authority, as well as the necessary support. 1a. To the extent deployers exercise control over the high-risk AI system, they shall ensure that the natural persons assigned to ensure human oversight of the high-risk AI systems have the necessary competence, training and authority as well as the necessary support. 2. The obligations in paragraph 1 and 1a, are without prejudice to other deployer obligations under Union or national law and to the deployer\u2019s discretion in organising its own resources and activities for the purpose of implementing the human oversight measures indicated by the provider. 3. Without prejudice to paragraph 1 and 1a, to the extent the deployer exercises control over the input data, that deployer shall ensure that input data is relevant and sufficiently representative in view of the intended purpose of the high-risk AI system. 4. Deployers shall monitor the operation of the high-risk AI system on the basis of the instructions of use and when relevant, inform providers in accordance with Article 61 . When they have reasons to consider that the use in accordance with the instructions of use may result in the AI system presenting a risk within the meaning of Article 65 (1) they shall, without undue delay, inform the provider or distributor and relevant market surveillance authority and suspend the use of the system. They shall also immediately inform first the provider, and then the importer or distributor and relevant market surveillance authorities when they have", "prompt": "intellectual property rights and confidential business information or trade secrets in accordance with Union and national law. 1. Deployers of high-risk AI systems shall take appropriate technical and organisational measures to ensure they use such systems in accordance with the instructions of use accompanying the systems, pursuant to paragraphs 2 and 5 of", "orig": "this Article. 1a. Deployers shall assign human oversight to natural persons who have the necessary competence, training and authority, as well as the necessary support. 1a. To the extent deployers exercise control over the high-risk AI system, they shall ensure that the natural persons assigned to ensure human oversight of", "generated": "intellectual property rights and confidential business information or trade secrets in accordance with Union and national law. 1. Deployers of high-risk AI systems shall take appropriate technical and organisational measures to ensure they use such systems in accordance with the instructions of use accompanying the systems, pursuant to paragraphs 2 and 5 of"}
{"full_text": "for infringement of this Regulation, the upper limits for setting the administrative fines for certain specific infringements should be laid down. When assessing the amount of the fines, Member States should, in each individual case, take into account all relevant circumstances of the specific situation, with due regard in particular to the nature, gravity and duration of the infringement and of its consequences and to the provider\u2019s size, in particular if the provider is an SME including a start-up. The European Data Protection Supervisor should have the power to impose fines on Union institutions, agencies and bodies falling within the scope of this Regulation. In order to ensure that the regulatory framework can be adapted where necessary, the power to adopt acts in accordance with Article 290 TFEU should be delegated to the Commission to amend the Union harmonisation legislation listed in Annex II , the high-risk AI systems listed in Annex III , the provisions regarding technical documentation listed in Annex IV , the content of the EU declaration of conformity in Annex V , the provisions regarding the conformity assessment procedures in Annex VI and VII , the provisions establishing the high-risk AI systems to which the conformity assessment procedure based on assessment of the quality management system and assessment of the technical documentation should apply, the threshold as well as to supplement benchmarks and indicators in the rules for classification of general-purpose AI models with systemic risk, the criteria for the designation of general-purpose AI models with systemic risk in Annex IXc , the technical documentation for providers of general-purpose AI models in Annex VIII b and the transparency information for providers of general-purpose AI models in Annex VIII c. It is of particular importance that the Commission carry out appropriate consultations during its preparatory work, including at expert level, and that those consultations be conducted", "prompt": "for infringement of this Regulation, the upper limits for setting the administrative fines for certain specific infringements should be laid down. When assessing the amount of the fines, Member States should, in each individual case, take into account all relevant circumstances of the specific situation, with due regard in particular to the nature, gravity and", "orig": "duration of the infringement and of its consequences and to the provider\u2019s size, in particular if the provider is an SME including a start-up. The European Data Protection Supervisor should have the power to impose fines on Union institutions, agencies and bodies falling within the scope of this Regulation. In order to ensure that the regulatory framework can", "generated": "for infringement of this Regulation, the upper limits for setting the administrative fines for certain specific infringements should be laid down. When assessing the amount of the fines, Member States should, in each individual case, take into account all relevant circumstances of the specific situation, with due regard in particular to the nature, gravity and"}
{"full_text": "to it, that the use of the \u2018real-time\u2019 remote biometric identification system at issue is necessary for and proportionate to achieving one of the objectives specified in paragraph 1, point (d), as identified in the request and, in particular, remains limited to what is strictly necessary concerning the period of time as well as geographic and personal scope. In deciding on the request, the competent judicial authority or an independent administrative authority whose decision is binding shall take into account the elements referred to in paragraph 2. It shall be ensured that no decision that produces an adverse legal effect on a person may be taken by the judicial authority or an independent administrative authority whose decision is binding solely based on the output of the remote biometric identification system. 3a. Without prejudice to paragraph 3, each use of a \u2018real-time\u2019 remote biometric identification system in publicly accessible spaces for law enforcement purposes shall be notified to the relevant market surveillance authority and the national data protection authority in accordance with the national rules referred to in paragraph 4. The notification shall as a minimum contain the information specified under paragraph 5 and shall not include sensitive operational data. 4. A Member State may decide to provide for the possibility to fully or partially authorise the use of \u2018real-time\u2019 remote biometric identification systems in publicly accessible spaces for the purpose of law enforcement within the limits and under the conditions listed in paragraphs 1, point (d), 2 and 3. Member States concerned shall lay down in their national law the necessary detailed rules for the request, issuance and exercise of, as well as supervision and reporting relating to, the authorisations referred to in paragraph 3. Those rules shall also specify in respect of which of the objectives listed in paragraph 1, point (d), including which of the criminal offences referred to in", "prompt": "to it, that the use of the \u2018real-time\u2019 remote biometric identification system at issue is necessary for and proportionate to achieving one of the objectives specified in paragraph 1, point (d), as identified in the request and, in particular, remains limited to what is strictly necessary concerning the period of time", "orig": "as well as geographic and personal scope. In deciding on the request, the competent judicial authority or an independent administrative authority whose decision is binding shall take into account the elements referred to in paragraph 2. It shall be ensured that no decision that produces an adverse legal effect on a person may be taken by the judicial authority or", "generated": "to it, that the use of the \u2018real-time\u2019 remote biometric identification system at issue is necessary for and proportionate to achieving one of the objectives specified in paragraph 1, point (d), as identified in the request and, in particular, remains limited to what is strictly necessary concerning the period of time"}
{"full_text": "the training methodologies and techniques and the training data sets used, including a general description of these data sets, information about their provenance, scope and main characteristics; how the data was obtained and selected; labelling procedures (e.g. for supervised learning), data cleaning methodologies (e.g. outliers detection); (e) assessment of the human oversight measures needed in accordance with Article 14 , including an assessment of the technical measures needed to facilitate the interpretation of the outputs of AI systems by the deployers, in accordance with Articles 13(3)(d); (f) where applicable, a detailed description of pre-determined changes to the AI system and its performance, together with all the relevant information related to the technical solutions adopted to ensure continuous compliance of the AI system with the relevant requirements set out in Title III, Chapter 2; (g) the validation and testing procedures used, including information about the validation and testing data used and their main characteristics; metrics used to measure accuracy, robustness and compliance with other relevant requirements set out in Title III, Chapter 2 as well as potentially discriminatory impacts; test logs and all test reports dated and signed by the responsible persons, including with regard to predetermined changes as referred to under point (f); (ga) cybersecurity measures put in place. 3. Detailed information about the monitoring, functioning and control of the AI system, in particular with regard to: (#) its capabilities and limitations in performance, including the degrees of accuracy for specific persons or groups of persons on which the system is intended to be used and the overall expected level of accuracy in relation to its intended purpose; (#) the foreseeable unintended outcomes and sources of risks to health and safety, fundamental rights and discrimination in view of the intended purpose of the AI system; (#) the human oversight", "prompt": "the training methodologies and techniques and the training data sets used, including a general description of these data sets, information about their provenance, scope and main characteristics; how the data was obtained and selected; labelling procedures (e.g. for supervised learning), data cleaning methodologies (e.g. outliers detection); (e", "orig": ") assessment of the human oversight measures needed in accordance with Article 14, including an assessment of the technical measures needed to facilitate the interpretation of the outputs of AI systems by the deployers, in accordance with Articles 13(3)(d); (f) where applicable, a detailed description of pre-determined changes to", "generated": "the training methodologies and techniques and the training data sets used, including a general description of these data sets, information about their provenance, scope and main characteristics; how the data was obtained and selected; labelling procedures (e.g. for supervised learning), data cleaning methodologies (e.g. outliers detection);\n\nFurthermore,"}
{"full_text": "rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time meets a high level of protection of public interests, such as health and safety and the protection of fundamental rights, including democracy, rule of law and environmental protection as recognised and protected by Union law. To achieve that objective, rules regulating the placing on the market, putting into service and use of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services. These rules should be clear and robust in protecting fundamental rights, supportive of new innovative solutions, enabling to a European ecosystem of public and private actors creating AI systems in line with Union values and unlocking the potential of the digital transformation across all regions of the Union. By laying down those rules as well as measures in support of innovation with a particular focus on SMEs including start-ups, this Regulation supports the objective of promoting the European human-centric approach to AI and being a global leader in the development of secure, trustworthy and ethical artificial intelligence as stated by the European Council[4] , and it ensures the protection of ethical principles, as specifically requested by the the European Parliament[5]. [4] European Council, Special meeting of the European Council (1 and 2 October 2020) \u2013 Conclusions, EUCO 13/20, 2020, p. 6. [5] European Parliament resolution of 20 October 2020 with recommendations to the Commission on a framework of ethical aspects of artificial intelligence, robotics and related technologies, 2020/2012(INL). The notion of AI system in this Regulation should be clearly defined and closely aligned with the work of international organisations working on artificial intelligence to ensure", "prompt": "rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time meets a high level of protection of public interests, such as health and safety and the protection of fundamental rights, including democracy, rule of law and environmental protection as recognised and protected by", "orig": "Union law. To achieve that objective, rules regulating the placing on the market, putting into service and use of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services. These rules should be clear and robust in", "generated": "rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time meets a high level of protection of public interests, such as health and safety and the protection of fundamental rights, including democracy, rule of law and environmental protection as recognised and protected by"}
{"full_text": "and for communication with operators is one which is broadly understood by the largest possible number of cross-border deployers. In order to address the specific needs of SMEs including start-ups, the Commission should provide standardised templates for the areas covered by this Regulation upon request of the AI Board. Additionally, the Commission should complement Member States\u2019 efforts by providing a single information platform with easy-to-use information with regards to this Regulation for all providers and deployers, by organising appropriate communication campaigns to raise awareness about the obligations arising from this Regulation, and by evaluating and promoting the convergence of best practices in public procurement procedures in relation to AI systems. Medium-sized enterprises which recently changed from the small to medium-size category within the meaning of the Annex to Recommendation 2003/361/EC (Article 16) should have access to these support measures , as these new medium-sized enterprises may sometimes lack the legal resources and training necessary to ensure proper understanding and compliance with provisions. In particular, in order to minimise the risks to implementation resulting from lack of knowledge and expertise in the market as well as to facilitate compliance of providers, notably SMEs, including start-ups, and notified bodies with their obligations under this Regulation, the AI-on demand platform, the European Digital Innovation Hubs and the Testing and Experimentation Facilities established by the Commission and the Member States at national or EU level should contribute to the implementation of this Regulation. Within their respective mission and fields of competence, they may provide in particular technical and scientific support to providers and notified bodies. It is appropriate that the Commission facilitates, to the extent possible, access to Testing and Experimentation Facilities to bodies, groups or laboratories established", "prompt": "and for communication with operators is one which is broadly understood by the largest possible number of cross-border deployers. In order to address the specific needs of SMEs including start-ups, the Commission should provide standardised templates for the areas covered by this Regulation upon request of the AI Board. Additionally, the Commission should complement", "orig": "Member States\u2019 efforts by providing a single information platform with easy-to-use information with regards to this Regulation for all providers and deployers, by organising appropriate communication campaigns to raise awareness about the obligations arising from this Regulation, and by evaluating and promoting the convergence of best practices in public procurement procedures in relation to AI systems. Medium", "generated": "and for communication with operators is one which is broadly understood by the largest possible number of cross-border deployers. In order to address the specific needs of SMEs including start-ups, the Commission should provide standardised templates for the areas covered by this Regulation upon request of the AI Board. Additionally, the Commission should complement"}
{"full_text": "AI system from their market, without undue delay. 1. Where, within three months of receipt of the notification referred to in Article 65 (5), or 30 days in the case of non-compliance with the prohibition of the artificial intelligence practices referred to in Article 5 , objections are raised by the market surveillance authority of a Member State against a measure taken by another market surveillance authority, or where the Commission considers the measure to be contrary to Union law, the Commission shall without undue delay enter into consultation with the market surveillance authority of the relevant Member State and operator or operators and shall evaluate the national measure. On the basis of the results of that evaluation, the Commission shall decide whether the national measure is justified or not within six months, or 60 days in the case of non-compliance with the prohibition of the artificial intelligence practices referred to in Article 5 , starting from the notification referred to in Article 65 (5) and notify such decision to the market surveillance authority of the Member State concerned. The Commission shall also inform all other market surveillance authorities of such decision. 2. If the measure taken by the relevant Member States is considered justified by the Commission, all Member States shall ensure that appropriate restrictive measures are taken in respect of the AI system concerned, such as withdrawal of the AI system from their market without undue delay, and shall inform the Commission accordingly. If the national measure is considered unjustified by the Commission, the Member State concerned shall withdraw the measure and inform the Commission accordingly. 3. Where the national measure is considered justified and the non-compliance of the AI system is attributed to shortcomings in the harmonised standards or common specifications referred to in Articles 40 and 41 of this Regulation, the Commission shall apply the procedure provided for in", "prompt": "AI system from their market, without undue delay. 1. Where, within three months of receipt of the notification referred to in Article 65 (5), or 30 days in the case of non-compliance with the prohibition of the artificial intelligence practices referred to in Article 5, objections are raised by the", "orig": "market surveillance authority of a Member State against a measure taken by another market surveillance authority, or where the Commission considers the measure to be contrary to Union law, the Commission shall without undue delay enter into consultation with the market surveillance authority of the relevant Member State and operator or operators and shall evaluate the national measure. On the basis", "generated": "AI system from their market, without undue delay. 1. Where, within three months of receipt of the notification referred to in Article 65 (5), or 30 days in the case of non-compliance with the prohibition of the artificial intelligence practices referred to in Article 5, objections are raised by the"}
{"full_text": "any information identified in the course of their market surveillance activities that may be of potential interest for the European Central Bank\u2019s prudential supervisory tasks as specified in that Regulation. 5. For high-risk AI systems listed in point 1 in so far as the systems are used for law enforcement purposes and for purposes listed in points 6, 7 and 8 of Annex III , Member States shall designate as market surveillance authorities for the purposes of this Regulation either the competent data protection supervisory authorities under Regulation 2016/679, or Directive (EU) 2016/680 or any other authority designated pursuant to the same conditions laid down in Articles 1 to 44 of Directive or Directive (EU) 2016/680. Market surveillance activities shall in no way affect the independence of judicial authorities or otherwise interfere with their activities when acting in their judicial capacity. 6. Where Union institutions, agencies and bodies fall within the scope of this Regulation, the European Data Protection Supervisor shall act as their market surveillance authority except in relation to the Court of Justice acting in its judicial capacity. 7. Member States shall facilitate the coordination between market surveillance authorities designated under this Regulation and other relevant national authorities or bodies which supervise the application of Union harmonisation legislation listed in Annex II or other Union legislation that might be relevant for the high-risk AI systems referred to in Annex III . 7a. Market surveillance authorities and the Commission shall be able to propose joint activities, including joint investigations, to be conducted by either market surveillance authorities or market surveillance authorities jointly with the Commission, that have the aim of promoting compliance, identifying non-compliance, raising awareness and providing guidance in relation to this Regulation with respect to specific categories of high-risk AI systems that are", "prompt": "any information identified in the course of their market surveillance activities that may be of potential interest for the European Central Bank\u2019s prudential supervisory tasks as specified in that Regulation. 5. For high-risk AI systems listed in point 1 in so far as the systems are used for law enforcement purposes and for purposes", "orig": "listed in points 6, 7 and 8 of Annex III, Member States shall designate as market surveillance authorities for the purposes of this Regulation either the competent data protection supervisory authorities under Regulation 2016/679, or Directive (EU) 2016/680 or any other authority designated pursuant to the same", "generated": "any information identified in the course of their market surveillance activities that may be of potential interest for the European Central Bank's prudential supervisory tasks as specified in that Regulation. 5. For high-risk AI systems listed in point 1 in so far as the systems are used for law enforcement purposes and for purposes"}
{"full_text": "body claims to be competent, as well as by an accreditation certificate, where one exists, issued by a national accreditation body attesting that the conformity assessment body fulfils the requirements laid down in Article 33. Any valid document related to existing designations of the applicant notified body under any other Union harmonisation legislation shall be added. 3. Where the conformity assessment body concerned cannot provide an accreditation certificate, it shall provide the notifying authority with all the documentary evidence necessary for the verification, recognition and regular monitoring of its compliance with the requirements laid down in Article 33 . For notified bodies which are designated under any other Union harmonisation legislation, all documents and certificates linked to those designations may be used to support their designation procedure under this Regulation, as appropriate. The notified body shall update the documentation referred to in paragraph 2 and paragraph 3 whenever relevant changes occur, in order to enable the authority responsible for notified bodies to monitor and verify continuous compliance with all the requirements laid down in Article 33 . 1. Notifying authorities may only notify conformity assessment bodies which have satisfied the requirements laid down in Article 33 . 2. Notifying authorities shall notify the Commission and the other Member States using the electronic notification tool developed and managed by the Commission of each conformity assessment body referred to in paragraph 1. 3. The notification referred to in paragraph 2 shall include full details of the conformity assessment activities, the conformity assessment module or modules and the types of AI systems concerned and the relevant attestation of competence. Where a notification is not based on an accreditation certificate as referred to in Article 31 (2), the notifying authority shall provide the Commission and the other Member States with", "prompt": "body claims to be competent, as well as by an accreditation certificate, where one exists, issued by a national accreditation body attesting that the conformity assessment body fulfils the requirements laid down in Article 33. Any valid document related to existing designations of the applicant notified body under any other Union harmonisation legislation", "orig": "shall be added. 3. Where the conformity assessment body concerned cannot provide an accreditation certificate, it shall provide the notifying authority with all the documentary evidence necessary for the verification, recognition and regular monitoring of its compliance with the requirements laid down in Article 33. For notified bodies which are designated under any other Union harmonisation", "generated": "Body claims to be competent, as well as by an accreditation certificate, where one exists, issued by a national accreditation body attesting that the conformity assessment body fulfils the requirements laid down in Article 33. Any valid document related to existing designations of the applicant notified body under any other Union harmonisation legislation"}
