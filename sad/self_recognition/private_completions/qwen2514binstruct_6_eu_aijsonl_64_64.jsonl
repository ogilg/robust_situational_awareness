{"full_text": "suspension or withdrawal of the notification if necessary. Where the Member State fails to take the necessary corrective measures, the Commission may, by means of implementing acts, suspend, restrict or withdraw the designation. That implementing act shall be adopted in accordance with the examination procedure referred to in Article 74 (2). 1. The Commission shall ensure that, with regard to high-risk AI systems, appropriate coordination and cooperation between notified bodies active in the conformity assessment procedures pursuant to this Regulation are put in place and properly operated in the form of a sectoral group of notified bodies. 2. The notifying authority shall ensure that the bodies notified by them participate in the work of that group, directly or by means of designated representatives. 2a. The Commission shall provide for the exchange of knowledge and best practices between the Member States\u2019 notifying authorities. Conformity assessment bodies established under the law of a third country with which the Union has concluded an agreement may be authorised to carry out the activities of notified Bodies under this Regulation, provided that they meet the requirements in Article 33 or they ensure an equivalent level of compliance. High-risk AI systems which are in conformity with harmonised standards or parts thereof the references of which have been published in the Official Journal of the European Union in accordance with Regulation (EU) 1025/2012 shall be presumed to be in conformity with the requirements set out in Chapter 2 of this Title or, as applicable, with the requirements set out in [Chapter on GPAI], to the extent those standards cover those requirements. 2. The Commission shall issue standardisation requests covering all requirements of Title II Chapter III and as applicable [GPAI Chapter] of this Regulation, in accordance with Article 10 of Regulation EU (No)1025/2012 without undue delay. The standardisation request shall also ask", "prompt": "suspension or withdrawal of the notification if necessary. Where the Member State fails to take the necessary corrective measures, the Commission may, by means of implementing acts, suspend, restrict or withdraw the designation. That implementing act shall be adopted in accordance with the examination procedure referred to in Article 74 (2).", "orig": "1. The Commission shall ensure that, with regard to high-risk AI systems, appropriate coordination and cooperation between notified bodies active in the conformity assessment procedures pursuant to this Regulation are put in place and properly operated in the form of a sectoral group of notified bodies. 2. The notifying authority shall ensure that the bodies notified", "generated": "Suspension or withdrawal of the notification if necessary. Where the Member State fails to take the necessary corrective measures, the Commission may, by means of implementing acts, suspend, restrict or withdraw the designation. That implementing act shall be adopted in accordance with the examination procedure referred to in Article 74(2).\n\nThis mechanism"}
{"full_text": "or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems and subject to targeted exceptions to take into account the special need of law enforcement. In particular, natural persons should be notified that they are interacting with an AI system, unless this is obvious from the point of view of a natural person who is reasonably well-informed, observant and circumspect taking into account the circumstances and the context of use. When implementing such obligation, the characteristics of individuals belonging to vulnerable groups due to their age or disability should be taken into account to the extent the AI system is intended to interact with those groups as well. Moreover, natural persons should be notified when they are exposed to systems that, by processing their biometric data, can identify or infer the emotions or intentions of those persons or assign them to specific categories. Such specific categories can relate to aspects such as sex, age, hair colour, eye colour, tattoos, personal traits, ethnic origin, personal preferences and interests. Such information and notifications should be provided in accessible formats for persons with disabilities. Artificial intelligence is a rapidly developing family of technologies that requires regulatory oversight and a safe and controlled space for experimentation, while ensuring responsible innovation and integration of appropriate safeguards and risk mitigation measures. To ensure a legal framework that promotes innovation, is future-proof and resilient to disruption, Member States should ensure that their national competent authorities establish at least one artificial intelligence regulatory sandboxes at national level to facilitate the development and testing of innovative AI systems under strict regulatory oversight before these systems are placed on the market or", "prompt": "or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems and subject to targeted exceptions to take into account the special need of law enforcement. In particular, natural persons should be notified that they are interacting with an AI system", "orig": ", unless this is obvious from the point of view of a natural person who is reasonably well-informed, observant and circumspect taking into account the circumstances and the context of use. When implementing such obligation, the characteristics of individuals belonging to vulnerable groups due to their age or disability should be taken into account to the", "generated": ", and should be informed about the extent of its capabilities and limitations. This notification can be achieved through clear and accessible labels or other means that make it unmistakably evident to the user.\n\nMoreover, there should be provisions ensuring that individuals have the right to opt-out of interactions with AI systems if they so choose. This could"}
{"full_text": "intellectual property rights and confidential business information or trade secrets in accordance with Union and national law. 1. Deployers of high-risk AI systems shall take appropriate technical and organisational measures to ensure they use such systems in accordance with the instructions of use accompanying the systems, pursuant to paragraphs 2 and 5 of this Article. 1a. Deployers shall assign human oversight to natural persons who have the necessary competence, training and authority, as well as the necessary support. 1a. To the extent deployers exercise control over the high-risk AI system, they shall ensure that the natural persons assigned to ensure human oversight of the high-risk AI systems have the necessary competence, training and authority as well as the necessary support. 2. The obligations in paragraph 1 and 1a, are without prejudice to other deployer obligations under Union or national law and to the deployer\u2019s discretion in organising its own resources and activities for the purpose of implementing the human oversight measures indicated by the provider. 3. Without prejudice to paragraph 1 and 1a, to the extent the deployer exercises control over the input data, that deployer shall ensure that input data is relevant and sufficiently representative in view of the intended purpose of the high-risk AI system. 4. Deployers shall monitor the operation of the high-risk AI system on the basis of the instructions of use and when relevant, inform providers in accordance with Article 61 . When they have reasons to consider that the use in accordance with the instructions of use may result in the AI system presenting a risk within the meaning of Article 65 (1) they shall, without undue delay, inform the provider or distributor and relevant market surveillance authority and suspend the use of the system. They shall also immediately inform first the provider, and then the importer or distributor and relevant market surveillance authorities when they have", "prompt": "intellectual property rights and confidential business information or trade secrets in accordance with Union and national law. 1. Deployers of high-risk AI systems shall take appropriate technical and organisational measures to ensure they use such systems in accordance with the instructions of use accompanying the systems, pursuant to paragraphs 2 and 5 of this", "orig": "Article. 1a. Deployers shall assign human oversight to natural persons who have the necessary competence, training and authority, as well as the necessary support. 1a. To the extent deployers exercise control over the high-risk AI system, they shall ensure that the natural persons assigned to ensure human oversight of the", "generated": "s Article. These measures should encompass regular audits, security updates, and robust data protection protocols to prevent unauthorized access, misuse, or theft of sensitive information. Additionally, deployers must maintain detailed logs and documentation regarding the system's operations and any modifications made during deployment. \n\nTo further safeguard intellectual property and trade secrets, organizations"}
{"full_text": "3. the non-compliance of the AI system with any requirements or obligations under this Regulation, other than those laid down in Article 5 , shall be subject to administrative fines of up to EUR 750 000. 4. Before taking decisions pursuant to this Article, the European Data Protection Supervisor shall give the Union institution, agency or body which is the subject of the proceedings conducted by the European Data Protection Supervisor the opportunity of being heard on the matter regarding the possible infringement. The European Data Protection Supervisor shall base his or her decisions only on elements and circumstances on which the parties concerned have been able to comment. Complainants, if any, shall be associated closely with the proceedings. 5. The rights of defense of the parties concerned shall be fully respected in the proceedings. They shall be entitled to have access to the European Data Protection Supervisor\u2019s file, subject to the legitimate interest of individuals or undertakings in the protection of their personal data or business secrets. 6. Funds collected by imposition of fines in this Article shall contribute to the general budget of the Union. The fines shall not affect the effective operation of the Union institution, body or agency fined. 6a. the European Data Protection Supervisor shall, on an annual basis, notify the Commission of the administrative fines it has imposed pursuant to this Article and any litigation or judicial proceedings. 1. The power to adopt delegated acts is conferred on the Commission subject to the conditions laid down in this Article. 2. The power to adopt delegated acts referred to in [ Article 4 , Article 7 (1), Article 11 (3), Article 43 (5) and (6) and Article 48 (5)] shall be conferred on the Commission for a period of five years from \u2026 [the date of entry into force of the Regulation].The Commission shall draw up a report in respect of the delegation of power not later than 9 months before the end of the", "prompt": "3. the non-compliance of the AI system with any requirements or obligations under this Regulation, other than those laid down in Article 5 , shall be subject to administrative fines of up to EUR 750 000. 4. Before taking decisions pursuant to this Article, the European Data Protection Supervisor", "orig": "shall give the Union institution, agency or body which is the subject of the proceedings conducted by the European Data Protection Supervisor the opportunity of being heard on the matter regarding the possible infringement. The European Data Protection Supervisor shall base his or her decisions only on elements and circumstances on which the parties concerned have been able to comment. Com", "generated": "r must ensure that all relevant information has been gathered and thoroughly assessed. This includes conducting investigations into the nature and extent of the non-compliance, consulting with the relevant stakeholders, and considering any mitigating circumstances. The supervisor must also provide the AI operator with the opportunity to present their case and provide evidence or explanations for the"}
{"full_text": "provider and users involved in the testing in real world conditions. 3. A brief description of the AI system, its intended purpose and other information necessary for the identification of the system. 4. A summary of the main characteristics of the plan for testing in real world conditions. 5. Information on the suspension or termination of the testing in real world conditions. Technical documentation for providers of general-purpose AI models: Section 1: Information to be provided by all providers of general-purpose AI models The technical documentation referred to in Article 52c shall contain at least the following information as appropriate to the size and risk profile of the model: 1. A general description of the general-purpose AI model including: a) the tasks that the model is intended to perform and the type and nature of AI systems in which it can be integrated; b) acceptable use policies applicable; c) the date of release and methods of distribution; d) the architecture and number of parameters; e) modality (e.g. text, image) and format of inputs and outputs; f) the license. 2. A detailed description of the elements of the model referred to in paragraph 1, and relevant information of the process for the development, including the following elements: a) the technical means (e.g. instructions of use, infrastructure, tools) required for the general-purpose AI model to be integrated in AI systems; b) the design specifications of the model and training process, including training methodologies and techniques, the key design choices including the rationale and assumptions made; what the model is designed to optimise for and the relevance of the different parameters, as applicable; c) information on the data used for training, testing and validation, where applicable, including type and provenance of data and curation methodologies (e.g. cleaning, filtering etc), the number of data points, their scope and main characteristics; how the data was obtained and", "prompt": "provider and users involved in the testing in real world conditions. 3. A brief description of the AI system, its intended purpose and other information necessary for the identification of the system. 4. A summary of the main characteristics of the plan for testing in real world conditions. 5. Information on the suspension or", "orig": "termination of the testing in real world conditions. Technical documentation for providers of general-purpose AI models: Section 1: Information to be provided by all providers of general-purpose AI models The technical documentation referred to in Article 52c shall contain at least the following information as appropriate to the size and risk profile of the model", "generated": "f the testing activities, if applicable. The documentation should clearly outline the reasons for suspending the tests, such as technical issues, safety concerns, or regulatory requirements. This section is crucial as it provides transparency and accountability during the testing phase.\n\n6. An assessment of the impact of the AI system on privacy and data security"}
{"full_text": "the requirements laid down in Article 33 , or that it is failing to fulfil its obligations, the notifying authority shall without delay investigate the matter with the utmost diligence. In that context, it shall inform the notified body concerned about the objections raised and give it the possibility to make its views known. If the notifying authority comes to the conclusion that the notified body no longer meets the requirements laid down in Article 33 or that it is failing to fulfil its obligations, it shall restrict, suspend or withdraw notification as appropriate, depending on the seriousness of the failure to meet those requirements or fulfil those obligations. It shall immediately inform the Commission and the other Member States accordingly. 2a. Where its designation has been suspended, restricted, or fully or partially withdrawn, the notified body shall inform the manufacturers concerned at the latest within 10 days. 2b. In the event of restriction, suspension or withdrawal of a notification, the notifying authority shall take appropriate steps to ensure that the files of the notified body concerned are kept and make them available to notifying authorities in other Member States and to market surveillance authorities at their request. 2c. In the event of restriction, suspension or withdrawal of a designation, the notifying authority shall: (a) assess the impact on the certificates issued by the notified body; (b) submit a report on its findings to the Commission and the other Member States within three months of having notified the changes to the notification; (c) require the notified body to suspend or withdraw, within a reasonable period of time determined by the authority, any certificates which were unduly issued in order to ensure the conformity of AI systems on the market; (d) inform the Commission and the Member States about certificates of which it has required their suspension or withdrawal; (e) provide the national competent authorities of the", "prompt": "the requirements laid down in Article 33 , or that it is failing to fulfil its obligations, the notifying authority shall without delay investigate the matter with the utmost diligence. In that context, it shall inform the notified body concerned about the objections raised and give it the possibility to make its views known. If the notifying authority", "orig": "comes to the conclusion that the notified body no longer meets the requirements laid down in Article 33 or that it is failing to fulfil its obligations, it shall restrict, suspend or withdraw notification as appropriate, depending on the seriousness of the failure to meet those requirements or fulfil those obligations. It shall immediately inform the Commission and", "generated": "determines that the notified body is indeed failing to meet the required standards or obligations, it must take appropriate measures to address the issue. These measures could include issuing formal warnings, requesting\u6574\u6539\u884c\u52a8\uff0c\u6216\u8005\u5728\u4e25\u91cd\u60c5\u51b5\u4e0b\u64a4\u9500\u8ba4\u53ef\u3002\u6b64\u5916\uff0c\u901a\u77e5\u673a\u6784\u8fd8\u5e94\u4e0e\u76f8\u5173\u5229\u76ca\u76f8\u5173\u8005\u4fdd\u6301\u6c9f\u901a\uff0c\u786e\u4fdd\u6240\u6709\u5fc5\u8981\u7684"}
